import requests
import string
import json
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

def fetch_rooms(query):
    url = "https://plan.zut.edu.pl/schedule.php"
    params = {"kind": "room", "query": query}
    try:
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list):
                # Zwracamy unikalne nazwy sal
                return [room.get('item') for room in data if 'item' in room]
            else:
                logging.warning(f"Nieprawidłowa odpowiedź API dla zapytania {query}: {data}")
                return []
        else:
            logging.error(f"Błąd pobierania sal dla {query}: {response.status_code}")
            return []
    except requests.exceptions.RequestException as e:
        logging.error(f"Problem z połączeniem dla zapytania {query}: {e}")
        return []
    except ValueError:
        logging.error(f"Nie udało się sparsować odpowiedzi JSON dla {query}")
        return []

def generate_queries():
    queries = []

    for number in range(1, 501):
        queries.append(str(number))

    for letter in string.ascii_uppercase:
        queries.append(letter)

    return queries

def scrape_rooms():
    queries = generate_queries()
    unique_rooms = set()

    logging.info(f"Rozpoczęcie scrapowania sal dla {len(queries)} zapytań...")

    with ThreadPoolExecutor(max_workers=50) as executor:
        futures = {executor.submit(fetch_rooms, query): query for query in queries}

        for future in as_completed(futures):
            query = futures[future]
            try:
                rooms = future.result()
                if rooms:
                    unique_rooms.update(rooms)
                    logging.info(f"Znaleziono {len(rooms)} sal dla zapytania '{query}'")
            except Exception as e:
                logging.error(f"Błąd podczas przetwarzania zapytania '{query}': {e}")

    save_to_file(list(unique_rooms))

def save_to_file(data, filename="rooms.json"):
    with open(filename, "w", encoding="utf-8") as file:
        json.dump(data, file, ensure_ascii=False, indent=4)
    logging.info(f"Zapisano {len(data)} sal do pliku '{filename}'")

if __name__ == "__main__":
    scrape_rooms()
